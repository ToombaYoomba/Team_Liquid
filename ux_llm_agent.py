import os
import json
import asyncio
from dotenv import load_dotenv
from openai import AsyncOpenAI

from minimal_agents.agent import Agent
from minimal_agents.runner import Runner
from minimal_agents.run_config import RunConfig
from util.adk_custom_model_provider import CustomModelProvider

from mcp_ux_server import _load_parquet_summary_direct

# Загружаем переменные окружения
load_dotenv()
folder_id = os.environ["folder_id"]
api_key = os.environ["api_key"]

model = f"gpt://{folder_id}/qwen3-235b-a22b-fp8/latest"

client = AsyncOpenAI(
    base_url="https://rest-assistant.api.cloud.yandex.net/v1",
    api_key=api_key,
    project=folder_id
)

REL_CHANGE_THRESHOLD = 0.3
Z_SCORE_THRESHOLD = 2.0

PROMPT_TEMPLATE = """
У тебя есть две JSON-сводки — VERSION_A и VERSION_B.

VERSION_A:
{version_a}

VERSION_B:
{version_b}

В сводках хранятся данные по UX 2-х версий сайтов: например количество кликов и проведённое время на каждой странице сайта и т.д. 
После считывания 2-х сводок ты анализируешь разницу между ними: увеличение числа кликов, времени на странице и т.д. 
Далее ты выделяешь сильно изменившееся метрики (изменения выходящие за какие-то нормальные границы). 
На основе этих изменившихся метрик ты определяешь проблему из следующего списка:

### Метрики для выявления проблем пользовательского опыта

#### 1. Проблема: Высокий отскок с ключевых страниц

Ключевые метрики:
- Bounce Rate (Показатель отказов)
  - *Расчет:* (Количество сессий с одной страницей / Все сессии на странице) × 100%
  - *Интерпретация:* Высокий процент показывает, что пользователи уходят без взаимодействия

- Exit Rate (Показатель выходов)
  - *Расчет:* (Количество выходов со страницы / Все просмотры страницы) × 100%
  - *Интерпретация:* Показывает, насколько часто страница является последней в сессии

- Time on Page (Время на странице)
  - *Расчет:* Среднее время всех пользователей на странице
  - *Интерпретация:* Низкое значение (<15 сек) указывает на нерелевантность контента

- Scroll Depth (Глубина скролла)
  - *Расчет:* Процент пользователей, доскроливших до ключевых точек (25%, 50%, 75%, 100%)
  - *Интерпретация:* Показывает, видят ли пользователи основной контент

#### 2. Проблема: «Блуждание» по сайту/приложению

Ключевые метрики:
- Pages per Session (Страниц за сессию)
  - *Расчет:* Общее количество просмотров страниц / Общее количество сессий
  - *Интерпретация:* Высокое значение без конверсии = бесцельное блуждание

- Navigation vs. Search Usage
  - *Расчет:* (Сессии с использованием поиска / Все сессии) × 100%
  - *Интерпретация:* Высокий процент = пользователи не могут найти нужное через навигацию

- Goal Conversion Rate
  - *Расчет:* (Сессии с конверсией / Все сессии) × 100%
  - *Интерпретация:* Низкое значение при высоком Pages per Session подтверждает проблему

#### 3. Проблема: Проблемы с навигацией

Ключевые метрики:
- Количество использований кнопки "Назад"
  - *Расчет:* Отслеживание события "клик по кнопке Назад"
  - *Интерпретация:* Частое использование = пользователи теряются

- Время до первого клика
  - *Расчет:* Среднее время от загрузки страницы до первого взаимодействия с навигацией
  - *Интерпретация:* Долгий поиск = неинтуитивная навигация

- Повторные переходы "Главная → Меню → Главная"
  - *Расчет:* Анализ последовательности переходов в аналитике
  - *Интерпретация:* Пользователи не могут найти нужный раздел

#### 4. Проблема: Ошибки ввода данных в формах

Ключевые метрики:
- Form Abandonment Rate
  - *Расчет:* (Незавершенные формы / Все начатые формы) × 100%
  - *Интерпретация:* Высокий процент = проблемы с юзабилити формы

- Field-Level Error Rate
  - *Расчет:* (Ошибки в поле / Все попытки заполнения) × 100%
  - *Интерпретация:* Показывает самые проблемные поля

- Time to Complete Form
  - *Расчет:* Среднее время заполнения и отправки формы
  - *Интерпретация:* Высокое значение = форма слишком сложная

- Количество фокусов на поле
  - *Расчет:* Количество активаций одного поля
  - *Интерпретация:* Много фокусов = пользователь сомневается в правильности ввода

#### 5. Проблема: Критические точки отказа в воронках

Ключевые метрики:
- Funnel Drop-off Rate
  - *Расчет:* (Пользователи, ушедшие на шаге N / Пользователи, дошедшие до шага N) × 100%
  - *Интерпретация:* Показывает самые проблемные шаги воронки

- Overall Conversion Rate
  - *Расчет:* (Пользователи, завершившие воронку / Пользователи, начавшие воронку) × 100%
  - *Интерпретация:* Общая эффективность всего процесса

- Funnel Step Efficiency
  - *Расчет:* (Пользователи на шаге N+1 / Пользователи на шаге N) × 100%
  - *Интерпретация:* Эффективность перехода между конкретными шагами

Далее ты выдаёшь список найденных проблем и метрики, относящиеся к каждой в json файле.
В самом json файле такая структура:
Имя страницы: 
    -> Имя проблемы
        -> Данные по относящимся к проблеме метрикам в файле 1
        -> Аналогичные данные по второму файлу
        -> Насколько стало лучше\хуже ввиде какого-то коэффициента

Порог relative_change = {rel_thr}, z_threshold = {z_thr}.
Генерируй строго JSON.
"""

agent = Agent(
    name="UX_MCP_Analyzer",
    instructions="Ты — аналитик UX, выполняй анализ строго по инструкции и возвращай только JSON.",
    model=model
)

rc = RunConfig(model_provider=CustomModelProvider(model, client))


async def run_analysis(file_a: str, file_b: str):
    """
    Основная функция анализа:
    - Загружает parquet-файлы как JSON
    - Формирует промпт для LLM
    - Запускает агента
    """
    json_a = _load_parquet_summary_direct(file_a)
    json_b = _load_parquet_summary_direct(file_b)

    prompt = PROMPT_TEMPLATE.format(
        version_a=json_a,
        version_b=json_b,
        rel_thr=REL_CHANGE_THRESHOLD,
        z_thr=Z_SCORE_THRESHOLD
    )

    result = await Runner.run(agent, input=prompt, run_config=rc)
    return result.final_output


if __name__ == "__main__":
    a = "ux_version_A.parquet"
    b = "ux_version_B.parquet"
    out = asyncio.run(run_analysis(a, b))

    try:
        parsed = json.loads(out)
        with open("ux_report_llm.json", "w", encoding="utf8") as f:
            json.dump(parsed, f, ensure_ascii=False, indent=2)
        print("Saved ux_report_llm.json")
    except json.JSONDecodeError:
        print("Invalid JSON from LLM:")
        print(out)
